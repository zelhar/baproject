\section{Appendix: Linear algebra primer}

\subsection*{}

\subsection*{}

\begin{mydef}
\label{Ax:def:transition} A \textbf{Transition Matrix } (we call
it a \textbf{Transition} in short), which is sometimes also called a
\textbf{stochastic matrix}, is a real valued non negative square
($n \times n$) matrix $A$ such that each of its columns sums up to one: $$A
\geq 0,\ \forall j \sum_i A_{i,j} = 1$$ $A$ acts from the left as a
linear mapping: $A:v \to A \cdot v$. In this paper we use left
multiplication convention ($Av$). There are many other publications
that deal with random walk and Markov processes, where right
multiplication is used ($v \cdot A$), and accordingly the rows are
normalized rather than the columns.

A transition is \textbf{positive}, designated by $A > 0$ if all its entries are positive.

A transition is \textbf{primitive} if for some $k>$ $A^k$ is positive. The same
property is called \textbf{regular} in some other sources.

A transition is \textbf{irreducible} if for every entry $A_{i,j}$ there is some $k$ such
that $A^k_{i,j} > 0$.

It can be shown that 
A matrix $A$ is 
irreducible by and only if it is NOT
similar by permutations matrices to a block upper triangular matrix
which means 
$
\nexists P : 
A =
P
\begin{pmatrix}
B & C \\
0 & D
\end{pmatrix}
P^{-1}
$

where $P$ is a permutation matrix and $B, C$ are square matrices of size greater than $0$.
\end{mydef}

\begin{mydef}
\label{Ax:def:state}
A \textbf{State} is a non-negative vector $v \in R^n$ s.t $\sum_i v_i = 1$.
\end{mydef}

\begin{remark}
\label{Ax:remark:state}
If $v$ is a
state and $A$ is a transition as defined in
\ref{Ax:def:transition}, then
  $Av$ is also a state because: 
$$\sum_i(Av)_i = \sum_j v_j(\sum_k A_{j,k}) = \sum_j v_j \cdot 1 = 1$$
Also its easy to confirm by multiplying with $e_i$, that if $Av$ is a state
for every state $v$ 
each column $A e_i$ must sum to $1$.
Therefore this is an equivalent definition for a transition.

If $A$ is a transition and $x,y$ are two states such that
$x \leq Ay$ then $x=y$.
\end{remark}

\begin{mydef}
\label{Ax:def:abs}
%changed C to R per Martin's request but it holds for C
Given $A \in \R^{n \times n}$ We let $|A| \in \R^{n \times n}$ be the resulting
matrix from applying $|\cdot|$ element wise. Given a vector $v \in \C^n$ we let
$|v| \in \R^n$ the corresponding non-negative vector.

We also let $A \gt 0, v \gt 0$ mean that it holds coordinate wise. 
\end{mydef}

Here is a very useful lemma for non-negative matrices which we will need later:
\begin{lemma}
\label{Ax:lem:eqal_by_vector}
Let $0 \leq A \leq B \in \R^{n \times n}$ 
and let $0 \lt v \in \R^n$.
If $Av = Bv$ then $A = B$.
\begin{proof}
Trivial.
\end{proof}
\end{lemma}

\begin{remark}
\label{Ax:remark:abs}
If $u \in \C^n$ is on the unit circle and $T$ a transition then
$|u|$ is a state, meaning $\||u|\|_1=1$, so $T|u|$ is also a state 
so $\|T|u|\|_1=1$.

We have (component-wise) $|Tu| \leq T|u|$. If $T>0$ and $u$ has negative or
non-real entries, then this inequality must be strict and
then $\|Tu\|_1 \lt \|T|u|\|_1 = 1$.
\end{remark}

\begin{lemma}
\label{Ax:lem:exist1}
If $T$ is a transition, then
there is a state $u$ such that $Tu = u$.
\begin{proof}
Because the columns of $A$ all sum to $1$, the columns of $A-I$ all sum to $0$.
Therefore $(1,1, \dots, 1)$ is an (left) eigenvector of the rows with eigenvalue $1$.
Therefore there is also some real (right) column eigenvector with eigenvalue $1$. 
(Also it follows from the Brouer fixed point theorem because $T$ maps the $l_1$
sphere to itself).

Let $u \in R^n$ be such vector: $Au=u$. Let $u = u^+ + u^-$ such that $u^- =
\min(u_i,0)$ and the other one defined similarly for the non-negative components.

Because $A$ is non-negative $A(u^+) \geq (Au)^+ \geq 0$,
and $A(u^-) \leq (Au)^- \leq 0$.

From $A$ being
non-negative and $(Au)^+ + (Au)^- = Au = u = u^+ + u^-$
And also $(A u)^+ = (u)^+$, so we must have $Au^+ \geq (Au)^+ = u^+$ 
(component wise). But if we had a strict inequality we would get:
$\|A(u^+/\|u^+\|_1)\|_1 > 1$ which is a contradiction to $A$ being a transition
matrix.

Then $A u^+ = u^+, A u^- = u^-$ and one of them must be non-zero. It follows
that $A$ has a non-negative eigenvector with eigenvalue $1$ (one of $u^+, -u^-$
which is non-zero). If we $l_1$-normalize that eigenvector it becomes a state.
\end{proof}
\end{lemma}


\begin{lemma}
\label{Ax:lem:uniq1}
If a transition $A \gt 0$ (or primitive)
, then it has exactly
one eigenvector $v$ with eigenvalue $1$ and in addition $v$ can be
chosen to be strictly positive.
Furthermore, for any other eigenvalue
$\lambda$ it holds that $|\lambda| \lt 1$.

If $A$ is just irreducible then then again $v>0$ and is unique but there may be
additional eigenvalues on the unit circle.

\begin{proof}
Let $A \gt 0$ be a transition. We already know that there exists at least one such eigenvector.
Let $u,v$ s.t $Au=u, Av=v$. 
We can assume these are real vectors because $A$ has only real entries.
Therefore we can choose $u,v$
to be states as we have already proven above.

Then let $w=u-v$. So $Aw = A(u-v) = u-v = w$. 
And $\sum_i w_i = 1 - 1 = 0$ by choice of $u,v$.

Like before $Aw^+ = w^+, Aw^- = w^-$
and because $w \neq 0$ but sums up to $0$, both $w^+, -w^- > 0$.
Because $w^-$ is non zero exactly on entries where $w^+$ is zero and vice versa, 
each of them must have at least one $0$ entry (and one none zero). But because
$A$ is strictly positive and $w^+$ is non-negative, $Aw^+$ must have ONLY
positive entries, contradicting $Aw^+ = w^+$. It follows then that $u-v=0$ is
the only possibility, hence the eigenvector with $1$ as eigenvalue is unique.

Suppose there is $Aw = \lambda w$ where $| \lambda|=1$. Choose $w$ so it is
$l_1$-normalized. Then $|w| = |Aw| \leq A \cdot |w|$ If $w$ has any negative or
complex coordinantes, then $|Aw| \lt A|w|$ and therefore 
$1 = \| |Aw| \|_1 \lt \|A|w|\|_1 =1$, a contradiction. Therefore there cannot be
any other eigenvalues on the unit circle.

Extending this for primitive matrix is easy because for some sufficiently big
$k$ $A^k \gt 0$. 

To prove the uniqueness of the $1$-eigenvector for the irreducible case, we have
$(\forall k \in \N) A^kw^+ = w^+$ and from that with some more work left undone
it follows that $w^+ > 0$ or
$w^+ = 0$.
\qedsymbol

\end{proof}
\end{lemma}

\begin{remark}
\label{Ax:remark:rhoisone}
The lemmas and theorems in this section are phrased in term of transitions. They
hold true in the more general case of positive/non-negative
linear transformations and one just replaces $1$ with the \textbf{spectral
radius} $ \rho = \rho(A)$.

In general a non-negative linear transformation has a \textbf{spectral radius}
$\rho = \rho(A)$ which is the absolute value of its greatest eigenvalue. In the case of
positive maps there is a unique single eigenvector with $\rho$ as the unique
greatest eigenvalue and so forth \dots. When we deal with a transition map,
lemma \ref{Ax:lem:uniq1} guaranties 
it has a spectral value of $\rho(A) = 1$.
\end{remark}

\begin{thm}
\label{Ax:thm:transition_ev}
Let $T$ be a positive (or primitive) transition. Then 

1. $1$ is the greatest eigenvalue
of $T$ and it has one unique eigenvector which is also positive,
so there exists a unique stationary state.

2. All the other eigenvalues have absolute value strictly less than $1$.

3. For every state $u$, $T^ku$ converges to the stationary state $\pi$.
In particular the columns of $T^k$ converge to $\pi$.

\begin{proof}
1 and 2. We already know.

3. There is a Jordan decomposition $T = PJP^{-1}$, such that $J$ is a Jordan
matrix, $J_{1,1} = 1$ and the rest of the main diagonal $|J_{i,i}| <1$.
So now the convergence is clear $J^k \to (e_1 | 0 \dots | 0)$.
For the matrix $P$ it must hold that $P = (P_1| \dots| P_n)$ and $P_1$ is the column 
eigenvector of $T$ corresponding to $1$ which we are free to $l_1$ normalize 
and the first row of $P^{-1}$ is the
left eigenvector corresponding to $1$ and so force \dots.

Some more work or literature check should confirm that $T^k \to (v|v\dots|v) = V$.
Then one can verify $Vu = v$ for any state $u$.
\end{proof}
\end{thm}

\begin{thm}
\label{Ax:thm:transition_irr_ev}
Let $T$ be an irreducible positive (or primitive) transition. 
Then:

1. Then $1$ is the greatest eigenvalue
of $T$ and it has one unique eigenvector which is also positive,
so there exists a unique stationary state.

2. If there are other other eigenvalues on the unit circle then their algebaic
multiplicity is equal their geometric multiplicity.

3. For every state $u$, the \textbf{Cesaro sums} 
$\frac{1}{n}\sum_{k=1}^n T^ku$ converge to the stationary state $\pi$.

\begin{proof}
1 We already know.

2. There is a Jordan decomposition $T = PJP^{-1}$. such that $J$ is a Jordan
matrix, $j_{1,1} = 1$ and the rest of the main diagonal $|J_{i,i}| \leq 1$.

If we had a Jordan block of size greater than $1$ for an eigenvalue $\lambda$,
Then on the superdiagonal of $J^k$ we would have $k \lambda$. If $|\lambda| =1$
then $J^k$ and hence $T^k$ would be unbounded, but that is impossible since
$T^k$ is a transition. If follows that all eigenvalues on the unit circle must
be semi simple (alebgaic multiplicity equals geometric).

3. For the convergence, it follows from calculations on the Jordan blocks, which
I omit. See \textcite{meyer2000matrix} or \textcite{serre2010matrices}
for rigorous proof.
\end{proof}
\end{thm}

What differs irreducible non-primitive matrices from primitive is
that they are periodical on their eigenvectors with complex eigenvalues
on the unit cycle. There is, in fact a wonderful theorem from Wielandt which
characterizes these Matrices:

\begin{thm}[Wielandt (1950)]
\label{Ax:thm:wielandt}
Let $A,B \in \C^{n \times n}$ such that $A \geq 0$ is irreducible and $|B| \leq
A$ (component-wise). Then $\rho(B) \leq \rho(A)$.
If $\rho(B)=\rho(A)$ then $|B|=A$, $B$ has an eigenvalue of the form $\mu =
\rho(A)e^{i \phi}$ and:

\begin{equation}
\begin{aligned}
\label{Ax:eq:wielandt1}
B &= 
e^{i \phi}DAD^{-1} \\ 
\text{where } D \text{ has the form:}\\
D &= 
\begin{pmatrix}
e^{\theta_1} & & & \\
& e^{\theta_2} & & \\
& & \ddots & \\
& & & e^{\theta_2}
\end{pmatrix}
\end{aligned}
\end{equation}

And conversely any $B$ of the form \ref{Ax:eq:wielandt1}
has $\rho(B) = \rho(A)$, $|B|=A$ and $\mu$ is an eigenvalue of $B$ which
corresponds to the eigenvalue $\rho(A)=|\mu|$ the greatest eigenvalue of $A$.

\begin{proof}
To see a rigorous proof I suggest \textcite{meyer2000matrix}.

The keys for proving this theorem are:
First WLG assume $A$ is a transition. This is possible because we may replace
$A$ with $AW^{-1}$, and $B$ with
$BW^{-1}$, where $W$ is the diagonal matrix that has the column-sums of $A$.
Since $A$ is irreducible it cannot have a column or a row that is all $0$
so this diagonal is positive $W$ is indeed invertible and later we can cancel out the
$W$'s and return to the general case.

Let $v$ be the $\mu$-eigenvector $Bv = \mu v, \|\mu|=1$ and choose it so that 
$\|v\|_1=1$.

Then 
\begin{equation}
|v| = |\mu v| = |B v| \leq |B| |v|
\leq A |v|
\end{equation}

Since $A$ is a transition by remark \ref{Ax:remark:state} $A|v|=|v|$. Since $A$ is
irreducible and $A|v| = |v|$ we must have by \ref{Ax:thm:transition_irr_ev} that
$|v| \gt 0$, and then by
lemma \ref{Ax:lem:eqal_by_vector} $A = |B|$ so that proves the first part.  

Now let $w = v / |v|$ (component-wise division) and let 
\[D = \text{diag}(w) = 
\begin{pmatrix}
e^{\theta_1} & & & \\
& e^{\theta_2} & & \\
& & \ddots & \\
& & & e^{\theta_2}
\end{pmatrix}
\]

Then $v = D|v|$, $|v|=D^{-1}v$ and we have:

\begin{equation}
\label{Ax:eq:wielandt1proof}
\begin{aligned}
A|v| &= |v| = D^{-1}v = \\
&= D^{-1} \mu^{-1} B v = \mu^{-1} D^{-1} BD|v|
\end{aligned}
\end{equation}

We know already that $|v| \gt 0$. If 
$C := \mu^{-1} D^{-1} BD$ contains any negative or complex entries, then
\ref{Ax:eq:wielandt1proof} cannot hold. It follows that
\[
A = C = \mu^{-1} D^{-1} BD 
\]

This proves the harder direction of the claim, the other direction is easy \qedsymbol.

\end{proof}
\end{thm}

The amazing consequence from \ref{Ax:thm:wielandt}:

\begin{thm}[Corollarly]
\label{Ax:thm:wielandt2}
If $A$ is irreducible transition with $h$ 
eigenvalues on the unit circle then its eigenvalues are exactly the $h$th unit roots
$\lambda_k = e^{2 \pi i k /h}, k = 0 \dots n-1$ and $A$ is similar to $\lambda
A$ by a diagonal matrix for any such eigenvalue.

\begin{proof}
Use theorem \ref{Ax:thm:wielandt} with $B=A$. If $|\lambda|=1$ is an eigenvalue
then $A = \lambda D A D^{-1}$. Since similarity doesn't change the eigenvalues,
$A$ and $\lambda A$ must have the same eigenvalues with the same multiplicity.
Since $1$ is a simple eigenvalue of $A$ and hence of $\lambda A$, and its
corresponding eigenvalue $\lambda$ is simple in $\lambda A$ and therefore in $A$
as well.

The matrices $\lambda_k A$, $k=0 \dots h$ are all similar, with $\lambda_0 = 1$
and $|\lambda_k| = 1, k=0 \dot h-1$ all simple eigenvalues. The only way for this to hold is if
$\{\lambda_k\}_0^{h-1}$ form a multiplicative group of order $h$ on the unit
circle, in other words, the eigenvalues are exactly all the $h$th unit roots. 
\end{proof}
\end{thm}

\begin{remark}
\label{Ax:remark:wielandt_cyclicity}
If $A$ is irreducible transition with exactly $h$ 
eigenvalues on the unit circle then $h$ is called the \textbf{period} of $A$.
$A \geq 0$ is primitive if and only if it is irreducible and aperiodic ($h=1$).

If $\omega = e^{2 \pi i /h}$ then \ref{Ax:thm:wielandt2} shows that $A = \omega D A
D^{-1}$. So if $\lambda$ is any eigenvalue not necessarily on the unit circle,
then $\omega \lambda$ is also an eigenvalue with the same multiplicity and
rotation with $\omega$ is an automorphism on the eigenvalues.

We may choose $D$ so that $D[1,1]=1$. If we reindex the dimension we can make
$D$ look like 
\[
D = [D_0 | \omega D_1 | \dots \omega^{h-1} D_{h-1}]
\] So Indexes corresponding to the same phase of the period appear sequentially.


Then use the identify $\forall k D^hA^{k} = A^k D^h$ and the fact that $A$ is
irreducible to show that $D^h = I$. Then use the identity $\omega DA = AD$ to
show that in the new indexing $A$ has the following periodical block structure
($0$ on the main diagonal):

\[
A = 
\begin{pmatrix}
0 & M_1 & 0 & \dots & 0 \\
0 & 0 & M_2 & 0 \dots & 0 \\
 &  & \ddots & \ddots & &  \\
0 & \dots & 0 & 0 & M_{h-1} \\
M_h & 0 & \dots & 0 & 0 
\end{pmatrix}
\]
\end{remark}


Now we will just present the Perron-Frobenius theorems. The main parts that are
important to our work have appeared in the previous theorems.

\begin{thm}[Perron-Frobenius \cite{meyer2000matrix}]
\label{Ax:thm:perron1}


Let $0 \lt A \in \R^{n \times n}$ with spectral radius $\rho := \rho(A)$, then the following are all true:
\begin{itemize}
\item{} $\rho \gt 0$
\item{} $\rho$ is a simple root of the characteristic polynomial of $A$,
in other words its algebraic multiplicity is $1$.
\item{} $(\exists v > 0) Av=\rho v$
\item{} If $Au = \lambda u$ and $\|u\|= \rho$ then $\lambda = \rho$
namely, $\rho$ is the unique eigenvalue on the spectral circle.
\item{(Collatz-Wielandt Formula)} $\rho = \max_{x \in \Gamma} \min_{i : x_i \neq 0} [Ax]_i / x_i$
with $\Gamma = \{x | x \geq 0, x \neq 0\}$
\end{itemize}
\end{thm}

\begin{thm}[Perron-Frobenius for irreducible matrices \autocite{meyer2000matrix}]
\label{Ax:thm:perron2}

Let $0 \leq A \in \R^{n \times n}$ be irreducible with spectral radius $\rho := \rho(A)$,
then the following are all true:
\begin{itemize}
\item{} $\rho \gt 0$
\item{} $\rho$ is a simple root of the characteristic polynomial of $A$,
in other words its algebraic multiplicity is $1$.
\item{} $(\exists v > 0) Av=\rho v$
\item{} There are no additional non-negative unit eigenvectors of $A$ other than
$v$. 
\item{(Collatz-Wielandt Formula)} $\rho = \max_{x \in \Gamma} \min_{i : x_i \neq 0} [Ax]_i / x_i$
with $\Gamma = \{x | x \geq 0, x \neq 0\}$
\end{itemize}
\end{thm}


